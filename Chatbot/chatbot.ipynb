{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "model = OllamaLLM(model=\"llama3\")\n",
    "\n",
    "class bot():\n",
    "    \n",
    "    chain: OllamaLLM\n",
    "    template: ChatPromptTemplate\n",
    "    conversation: list[tuple]\n",
    "\n",
    "    def __init__(self):\n",
    "        self.conversation = []\n",
    "\n",
    "    def system(self, text):\n",
    "        template = ChatPromptTemplate([\n",
    "        (\"system\", text),\n",
    "        (\"human\",\"{user_input}\")\n",
    "        ])\n",
    "        self.conversation = []\n",
    "        self.conversation.append((\"system\", text))\n",
    "        self.template = template\n",
    "\n",
    "    def sys_up(self):\n",
    "        self.template = ChatPromptTemplate(self.conversation + [(\"human\", \"{user_input}\")])\n",
    "        self.bind()\n",
    "\n",
    "    def bind(self):\n",
    "        self.chain = self.template | model\n",
    "    \n",
    "    def doc(self, path):\n",
    "        with open(path, 'r') as f:\n",
    "            text = f.read()\n",
    "        self.conversation.append([(\"system\", \"You will now receive text from the user that you need to remember and answer questions based on that text.\")])\n",
    "        self.conversation.append([(\"human\", text)])\n",
    "        self.sys_up()\n",
    "\n",
    "    def gen_out(self, text):\n",
    "        out = self.chain.invoke(text)\n",
    "        print(out, '\\n')\n",
    "        self.conversation.append((\"human\", text))\n",
    "        self.conversation.append((\"ai\", out))\n",
    "        self.sys_up()\n",
    "\n",
    "    def get_conv(self):\n",
    "        for dialogue in cb1.conversation:\n",
    "            print(dialogue)\n",
    "\n",
    "# cb1 = bot()\n",
    "# #Can change prompts as required to fine tune chatbot\n",
    "# sys_text = \"You are a helpful AI assistant. You will only answer if your name 'Bob' is called, and in a breif and precise manner. You will also remember previous user messages and answer based on the context\"\n",
    "\n",
    "# cb1.system(sys_text)\n",
    "# cb1.bind()\n",
    "# cb1.gen_out(\"What is 5+5? Bob\")\n",
    "# cb1.get_conv()\n",
    "# print(cb1.template)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb2 = bot()\n",
    "sys_text = \"You are an AI assistant. If you are given text in the format remember(text) then you will remember the text to answer further questions. You will receive the entire conversation \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = input(\"enter name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = 0\n",
    "while ch != 4:\n",
    "    print(\"1. Enter text\")\n",
    "    print(\"2. Enter Document\")\n",
    "    ch = int(input(\"Enter Choice\"))\n",
    "    if ch == 1:\n",
    "        s = input(\"\\nText:\")\n",
    "        cb2.gen_out(s)\n",
    "    elif ch == 2:\n",
    "        s = input(\"\\nEnter Path:\")\n",
    "        cb2.doc(s)\n",
    "        print(\"Memory Updated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
